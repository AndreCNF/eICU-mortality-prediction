{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Bag Test\n",
    "---\n",
    "\n",
    "Experimenting applying an embedding bag (embedding layer + average of all embedding vectors) on the categorical features of a time series dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd                # Dask to handle big data in dataframes\n",
    "import pandas as pd                        # Pandas to load the data initially\n",
    "from dask.distributed import Client        # Dask scheduler\n",
    "import numpy as np                         # Mathematical operations package, allowing also for missing values representation\n",
    "import torch                               # PyTorch for tensor and deep learning operations\n",
    "import data_utils as du                    # Data science and machine learning relevant methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust                           # Debugging in Jupyter Notebook cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame([[103, 0, 'dog'], \n",
    "                        [103, 0, 'cat'],\n",
    "                        [103, 1, 'horse'],\n",
    "                        [104, 0, 'bunny'],\n",
    "                        [104, 1, np.nan],\n",
    "                        [105, 0, 'horse'],\n",
    "                        [105, 0, 'dog'],\n",
    "                        [105, 0, 'cat'],\n",
    "                        [105, 0, 'bunny'],\n",
    "                        [105, 1, 'bunny'],\n",
    "                        [105, 1, 'dog'],\n",
    "                        [105, 1, np.nan],\n",
    "                        [105, 1, 'horse']], columns=['id', 'ts', 'Var0'])\n",
    "# Only use the line of code bellow if you want to test on Dask\n",
    "# data_df = dd.from_pandas(data_df, npartitions=2)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data_df\n",
    "# data_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding matrix used in the embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_mtx = torch.FloatTensor([[0, 0, 0],\n",
    "                               [-1, 0, 1],\n",
    "                               [0, 1, -1],\n",
    "                               [1, 1, 0],\n",
    "                               [1, -1, 1]])\n",
    "embed_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_embed_layer = torch.nn.Embedding.from_pretrained(embed_mtx)\n",
    "simple_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer + average operation (bagging):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_embed_layer = torch.nn.EmbeddingBag.from_pretrained(embed_mtx)\n",
    "bag_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "data_df.Var0, enum_dict = du.embedding.enum_categorical_feature(data_df, 'Var0', forbidden_digit=0)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data_df\n",
    "# data_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data = torch.tensor(data_df.values)\n",
    "# data = torch.tensor(data_df.compute().values)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_embed_layer(data[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data_df = pd.DataFrame(torch.cat((data[:, :2].float(), simple_embed_layer(data[:, 2])), dim=1).numpy(), columns=['id', 'ts', 'E0', 'E1', 'E2'])\n",
    "# Only use the line of code bellow if you want to test on Dask\n",
    "# embed_data_df = dd.from_pandas(embed_data_df, npartitions=2)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "embed_data_df\n",
    "# embed_data_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply embedding bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate rows that have the same `id` and `ts`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Var0 = data_df.Var0.astype(str)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data_df.Var0\n",
    "# data_df.Var0.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = du.embedding.join_categorical_enum(data_df, cat_feat='Var0', id_columns=['id', 'ts'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to a PyTorch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = du.embedding.string_encod_to_numeric(data_df, cat_feat='Var0', inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_dict = du.padding.get_sequence_length_dict(data_df, id_column='id', ts_column='ts')\n",
    "seq_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = du.padding.dataframe_to_padded_tensor(data_df, id_column='id', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the embedding bag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the idx of the column that we want to embed\n",
    "Var0idx = du.search_explore.find_col_idx(data_df, feature='Var0')\n",
    "Var0idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = du.utils.get_full_number_string(data[2, 1, 2].item())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = du.utils.get_full_number_string(data[2, 0, 2].item())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "Var0_embed, Var0_offset = du.embedding.prepare_embed_bag(data, feature=Var0idx)\n",
    "print(f'Var0_embed: {Var0_embed}')\n",
    "print(f'Var0_offset: {Var0_offset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Create and run a method that does the full embedding values calculation\n",
    "# and tensor joining pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_embed_layer(Var0_embed, Var0_offset)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "eicu-mortality-prediction",
   "language": "python",
   "name": "eicu-mortality-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
