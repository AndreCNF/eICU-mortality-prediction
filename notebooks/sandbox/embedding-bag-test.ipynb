{"cells":[{"cell_type":"markdown","metadata":{},"outputs":[],"source":["# Embedding Bag Test\n","---\n","\n","Experimenting applying an embedding bag (embedding layer + average of all embedding vectors) on the categorical features of a time series dataframe."]},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Import the necessary packages"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import dask.dataframe as dd                # Dask to handle big data in dataframes\nimport pandas as pd                        # Pandas to load the data initially\nfrom dask.distributed import Client        # Dask scheduler\nimport torch                               # PyTorch for tensor and deep learning operations\nimport data_utils as du                    # Data science and machine learning relevant methods"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Initialize variables"]},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["Data that we'll be using:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"data_df = pd.DataFrame([[103, 0, 'dog'], \n                        [103, 0, 'cat'],\n                        [103, 1, 'horse'],\n                        [104, 0, 'bunny'],\n                        [105, 0, 'horse'],\n                        [105, 0, 'dog'],\n                        [105, 0, 'cat'],\n                        [105, 0, 'bunny'],\n                        [105, 1, 'bunny'],\n                        [105, 1, 'dog'],\n                        [105, 1, 'horse']], columns=['id', 'ts', 'Var0'])\n# Only use the line of code bellow if you want to test on Dask\n# data_df = dd.from_pandas(data_df, npartitions=2)\n# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\ndata_df\n# data_df.compute()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"Embedding matrix used in the embedding layer:"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"embed_mtx = torch.FloatTensor([[0, 0, 0],\n                               [-1, 0, 1],\n                               [0, 1, -1],\n                               [1, 1, 0],\n                               [1, -1, 1]])\nembed_mtx"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"Simple embedding layer:"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"simple_embed_layer = torch.nn.Embedding.from_pretrained(embed_mtx)\nsimple_embed_layer"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"Embedding layer + average operation (bagging):"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"bag_embed_layer = torch.nn.EmbeddingBag.from_pretrained(embed_mtx)\nbag_embed_layer"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"## Enumerate categories"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"data_df.Var0, enum_dict = du.embedding.enum_categorical_feature(data_df, 'Var0')\n# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\ndata_df\n# data_df.compute()"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"enum_dict"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\ndata = torch.tensor(data_df.values)\n# data = torch.tensor(data_df.compute().values)\ndata"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"## Apply embedding layer"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"simple_embed_layer(data[:, 2])"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"embed_data_df = pd.DataFrame(torch.cat((data[:, :2].float(), simple_embed_layer(data[:, 2])), dim=1).numpy(), columns=['id', 'ts', 'E0', 'E1', 'E2'])\n# Only use the line of code bellow if you want to test on Dask\n# embed_data_df = dd.from_pandas(embed_data_df, npartitions=2)\n# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\nembed_data_df\n# embed_data_df.compute()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Apply embedding bag"]},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["Concatenate rows that have the same `id` and `ts`:"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":"data_df.Var0 = data_df.Var0.astype(str)\n# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\ndata_df.Var0\n# data_df.Var0.compute()"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"data_df = data_df.groupby(['id', 'ts']).Var0.apply(lambda x: \"%s\" % ';'.join(x)).to_frame().reset_index()\n# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\ndata_df\n# data_df.compute()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":"Apply the embedding bag:"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"Var0_embed, Var0_offset = du.embedding.prepare_embed_bag(data_df, 'Var0')\nprint(f'Var0_embed: {Var0_embed}')\nprint(f'Var0_offset: {Var0_offset}')"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"bag_embed_layer(Var0_embed, Var0_offset)[:-1]"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}