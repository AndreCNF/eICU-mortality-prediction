{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Handling multiple encodings and joins\n",
    "---\n",
    "\n",
    "Experimenting converting encodings back into string-formated categories and joining two different encoding dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "KOdmFzXqF7nq",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "G5RrWE9R_Nkl"
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd                # Dask to handle big data in dataframes\n",
    "import pandas as pd                        # Pandas to load the data initially\n",
    "from dask.distributed import Client        # Dask scheduler\n",
    "import os                                  # os handles directory/workspace changes\n",
    "import numpy as np                         # NumPy to handle numeric and NaN operations\n",
    "from tqdm import tqdm_notebook             # tqdm allows to track code execution progress\n",
    "from IPython.display import display        # Display multiple outputs on the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Change to parent directory\n",
    "os.chdir(\"..\")\n",
    "import utils                               # Contains auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Debugging packages\n",
    "import pixiedust                           # Debugging in Jupyter Notebook cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Change to parent directory (presumably \"Documents\")\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "# Path to the CSV dataset files\n",
    "data_path = 'Datasets/Thesis/eICU/uncompressed/'\n",
    "project_path = 'GitHub/eICU-mortality-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Set up local cluster\n",
    "client = Client(\"tcp://127.0.0.1:60773\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Upload the utils.py file, so that the Dask cluster has access to relevant auxiliary functions\n",
    "client.upload_file(f'{project_path}NeuralNetwork.py')\n",
    "client.upload_file(f'{project_path}utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "client.run(os.getcwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Creating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Encoded dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data1_df = pd.DataFrame([[103, 0, 1], \n",
    "                         [103, 0, 0],\n",
    "                         [103, 1, 0],\n",
    "                         [104, 0, '3;1;6'],\n",
    "                         [105, 0, '2;4'],\n",
    "                         [106, 0, 5],\n",
    "                         [107, 0, 0],\n",
    "                         [108, 0, '1;2;3'],\n",
    "                         [108, 1, 0],\n",
    "                         [108, 2, '3;5;1;6;2'],\n",
    "                         [108, 3, 6]], columns=['id', 'ts', 'Var0'])\n",
    "data2_df = pd.DataFrame([[217, 0, 0], \n",
    "                         [217, 1, 3],\n",
    "                         [217, 2, '3;4'],\n",
    "                         [426, 0, '1;2'],\n",
    "                         [409, 0, '2;4'],\n",
    "                         [378, 0, 1],\n",
    "                         [290, 0, 0]], columns=['id', 'ts', 'Var0'])\n",
    "# Only use the line of code bellow if you want to test on Dask\n",
    "data1_df = dd.from_pandas(data1_df, npartitions=2)\n",
    "data2_df = dd.from_pandas(data2_df, npartitions=2)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "# data1_df\n",
    "# data2_df\n",
    "print(f'Dataframe 1:')\n",
    "display(data1_df.compute())\n",
    "print(f'Dataframe 2:')\n",
    "display(data2_df.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Encoding dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data1_dict = {0: 'nan',\n",
    "              1: 'banana',\n",
    "              2: 'orange',\n",
    "              3: 'apple',\n",
    "              4: 'strawberry',\n",
    "              5: 'melon',\n",
    "              6: 'peach'}\n",
    "data2_dict = {0: 'nan',\n",
    "              1: 'orange',\n",
    "              2: 'pear',\n",
    "              3: 'blueberry',\n",
    "              4: 'banana'}\n",
    "print(f'Dictionary for data 1: \\n{data1_dict}')\n",
    "print(f'Dictionary for data 2: \\n{data2_dict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Converting encodings to the original category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x = '1;2;3;4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "enums = str(x).split(';')\n",
    "enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categories = [data1_dict[int(n)] for n in enums]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categories = ';'.join(categories)\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Get the categories names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data1_df['Var0_categories'] = data1_df.apply(lambda df: utils.enum_category_conversion(df, enum_column='Var0', enum_dict=data1_dict),\n",
    "                                             axis=1, meta=('df', str))\n",
    "data1_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data2_df['Var0_categories'] = data2_df.apply(lambda df: utils.enum_category_conversion(df, enum_column='Var0', enum_dict=data2_dict),\n",
    "                                             axis=1, meta=('df', str))\n",
    "data2_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Recover the enumerations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data1_df['Var0_num'] = data1_df.apply(lambda df: utils.enum_category_conversion(df, enum_column='Var0_categories', enum_dict=utils.invert_dict(data1_dict)),\n",
    "                                      axis=1, meta=('df', str))\n",
    "data1_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data2_df['Var0_num'] = data2_df.apply(lambda df: utils.enum_category_conversion(df, enum_column='Var0_categories', enum_dict=utils.invert_dict(data2_dict)),\n",
    "                                      axis=1, meta=('df', str))\n",
    "data2_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Joining two encodings into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "utils.invert_dict(data1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "utils.invert_dict(data2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "new_data1_df, new_data2_df, all_data_dict = utils.converge_enum(data1_df, data2_df, 'Var0', \n",
    "                                                                utils.invert_dict(data1_dict), \n",
    "                                                                utils.invert_dict(data2_dict))\n",
    "all_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "new_data1_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "new_data2_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "all_categories = set(list(data1_dict.values()) + list(data2_dict.values()))\n",
    "all_categories.remove('nan')\n",
    "all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data3_dict = {'nan': 0,\n",
    "              'orange': 1,\n",
    "              'unknown': 0,\n",
    "              'other': 0,\n",
    "              'pear': 2,\n",
    "              'blueberry': 3,\n",
    "              'banana': 4,\n",
    "              'null': 0}\n",
    "data3_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data3_dict = utils.invert_dict(data3_dict)\n",
    "data3_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data3_dict[0] = 'nan'\n",
    "data3_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Experiment with eICU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eicu-mortality-prediction",
   "language": "python",
   "name": "eicu-mortality-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
